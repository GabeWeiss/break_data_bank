This document is primarily for testing purposes. In terms of production usage, only the Orchestrator API is needed, the rest of the services are called from the Orchestrator and don't generally need to be called separately. The exception is if you're not using the build script, and creating your own database resources, then the /add endpoint on the db-lease service can be used to add the resource metadata to Firestore.

--------------------------------------------------------------------

Orchestrator - responsible for the front-end interface. Handles requests for load runs from front-end, and orchestrates the various services to gather the pieces the demo needs. Also creates a uuid for a load-generating job which is used by downstream services.

endpoints:
/ [GET]
  - Returns a list of endpoints for the API

/test [GET, POST]
  - Debug endpoint, doesn't do anything specific, but was used in debugging various pieces

/fail [POST]
  - Used for first step of demo. Triggers a load generating run that is designed to fail the db instance it runs against (Cloud SQL small instance with highest level of intensity of traffic)
  - Returns an array of job codes (1) which will be the collection name in Firestore where the transaction values will be set
    - key: { jobs_id: [] }
  - Parameters
    - 'read_pattern' (required)
      - integer from 1-3, representing 3 different types of patterns:
        - 1: Consistent low frequency
        - 2: Consistent high frequency
        - 3: Spikey
    - 'write_pattern' (required)
      - integer from 1-3, representing 3 different types of patterns (same as above)

/run [POST]
  - Used for final step of demo. Triggers 3 load generating runs. One for each type of database (Cloud SQL, Cloud SQL w/ replication, Cloud Spanner)
  - Returns an array of job codes (3) which will be the collection name in Firestore where the transaction values will be set
    - key: { jobs_id: [] }
  - Parameters
    - 'read_pattern' (required)
    - 'write_pattern' (required)
    - 'intensity' (required)
      - How powerful the read/write patterns will be. Takes an integer between 1-3.
    - 'sql_size' (required)
      - Power level of the db's underlying machine. Takes an integer between 1-3.
    - 'sql_rep_size' (required)
    - 'spanner_size' (required)

/cached [POST]
  - Another way to run the demo. This, instead of accessing the db's directly to run the load generation, returns
  - Returns an array of job codes (depends on which mode that was sent, 1 or 3) which will be the collection name in Firestore where the transaction values will be set
    - key: { jobs_id: [str] }
  - Parameters
    - 'mode' (required)
      - Takes a string "fail" or "run" depending on which mode is desired.
    - 'read_pattern' (required)
    - 'write_pattern' (required)
    - 'intensity' (required for run mode only)
    - 'sql_size' (required for run mode only)
    - 'sql_rep_size' (required for run mode only)
    - 'spanner_size' (required for run mode only)


db-lease - Responsible for managing the availability of db instances for the demo, as well as cleaning them up to prep for the next demo run

endpoints:
/ [GET]
/isitworking [GET]
  - Ping to verify service up
  - Returns 200

/add [POST]
  - Will add metadata to Firestore representing the db resource which then allows it to be checked out by the /lease endpoint for use in the demo
  - Returns a 200 status if the entry was added to Firestore, otherwise returns 500
  - Parameters
    - 'database_type' (required)
      - integer from 1-3, representing 3 different types of databases
        - 1: Cloud SQL
        - 2: Cloud SQL w/ replication
        - 3: Cloud Spanner
    - 'database_size' (required)
      - Power level of the db's underlying machine. Takes an integer between 1-3.
    - 'resource_id' (required)
      - Resource ID from GCP project
    - 'connection_string' (required)
      - IP address for Cloud SQL and Cloud SQL w/ replication, resource id for Cloud Spanner
    - 'replica_ip' (required for Cloud SQL w/ replication)
      - String. IP address of the read replica.

/lease [POST]
  - For the given DB type and size, checks out a database resource for use by the demo
  - Returns a JSON response object representing the requested resource
    - key: { resource_id: str, expiration: long, connection_string: str, replica_ip: str }
  - Parameters
    - 'database_type' (required)
      - integer from 1-3, representing 3 different types of databases
    - 'database_size' (required)
      - Power level of the db's underlying machine. Takes an integer between 1-3.
    - 'duration' (required)
      - How long (in seconds) to lease the database before the cleanup script runs against it

/force-clean [POST]
  - Resets the any DBs that are currently in an in-use or bad state
  - Only ever returns 200 currently


load-gen-service - Responsible for scheduling the load generating process itself in the Kubernetes cluster. Schedules the k8s job and runs the load-gen-script there.

endpoints:
/ [GET]
  - Test endpoint to verify service is up.

/ [POST]
  - Initiates a load generation job
  - Returns 200 on a successful load generating job creation
  - Parameters
    - 'job_id' (required)
      - Takes a string. This is provided by the orchestrating service. Represents a uuid where the transaction latency and failure results will end up stored in Firestore
    - 'database_type' (required)
      - integer from 1-3, representing 3 different types of databases
    - 'connection_string' (required)
      - String. Private IP for Cloud SQL and SQL w/ replication, resource id for Cloud Spanner
    - 'read_pattern' (required)
      - integer from 1-3, representing 3 different types of patterns:
        - 1: Consistent low frequency
        - 2: Consistent high frequency
        - 3: Spikey
    - 'write_pattern' (required)
      - integer from 1-3, representing 3 different types of patterns (same as above)
    - 'intensity' (required)
      - How powerful the read/write patterns will be. Takes an integer between 1-3.
    - 'replica_ip' (required for Cloud SQL w/ replication)
      - String. IP address of the read replica.
