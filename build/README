This is the build directory for the demo/tool known as "Breaking the Data Bank". There are two scripts that can be run:

build.py - builds the full live version of the demo and actually runs the loads live against our databases
build_cached.py - builds a trimmed down version of the demo which relies upon real, but cached data.

The following applies to the build.py script, notes on the build_cached.py can be found at the bottom.

Prerequisite software installations:

Python 3.x (https://www.python.org/downloads/)
Docker (https://www.docker.com/products/docker-desktop if not on Linux)
Java Dev Kit (https://www.oracle.com/java/technologies/javase-jdk14-downloads.html and be sure to add the JAVA_HOME variable pointed to the JDK install directory)
Maven (https://maven.apache.org/download.cgi)
Gcloud (https://cloud.google.com/sdk/install)
GSutil (Gcloud also installs GSUtil)
Firebase CLI (https://firebase.google.com/docs/cli)

Prerequisite setup:

You'll need to create a project that you have owner level privileges on. I THINK you could get by with lesser privileges, but since this is for demo purposes, and not production, I'm fine with just leaving it at owner level permissions.

Gcloud needs to have been initialized into the project where you want the demo to be staged.

This means you need to run `gcloud init` in the terminal window where you will run this script and configure to the project you've created.

Passing in the region flag (-r) is required for the script. The region is specifically what part of the world, and not the GCP region. The accepted values are "usa", "emea", "apac". Specific regions are picked by the script as they are different allowable regions for each product.

The other required flag to pass in is a version string with a -v flag. This string is formatted like: `-v v0.0.1` for example. This is necessary because of how the load generating script is run (kubernetes job). The container won't automatically re-fetch the container if there are changes unless the tag is different. So the version was a necessary evil to represent changes to the container tagging.

Quickstart would be:

`gcloud init`
`python build.py -v v0.0.1 -r usa`

The final output of the script will contain the URL for the orchestrator script if you want to trigger the back-end manually (instructions for running this manually to follow), as well as the URL for the hosted front-end which is a pretty and animated interface.



The list of products this demo touches in full run mode is:

Cloud SQL
Cloud Spanner
Container Registry
Cloud Run
Kubernetes Engine
Pub/Sub
Cloud Storage
Dataflow
Firestore

In cached mode the list of products is:

Cloud SQL
Cloud Spanner
Container Registry
Cloud Run
Firestore

Note, the data shown in the cached version IS still real. It was generated using the real version, and transferred over to a cached store in Firestore.

This demo running in full mode is pretty expensive to run. We hit all the products listed above quite hard. The traffic generated by the demo numbers in the 100,000s of queries per second, and those queries are all tracked through the databases as well as Pub/Sub and Dataflow.
