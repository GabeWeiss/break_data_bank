This is the build directory for the demo/tool known as "Breaking the Data Bank". There are two scripts that can be run:

build.py - builds the full live version of the demo and actually runs the loads live against our databases
build_cached.py - builds a trimmed down version of the demo which relies upon real, but cached data.

The following applies to the build.py script, notes on the build_cached.py can be found at the bottom.

Prerequisite software installations:

Python 3.x
Docker
Maven
Gcloud and GSutil tools
Firebase CLI

Prerequisite setup:

Gcloud needs to have been initialized into the project (but not necessarily authorized, the script does this as part of the run) where you want the demo to be staged.

This means you need to run `gcloud init` in the terminal window where you will run this script and configure to the project. You can set a default compute region if you wish, which should be closests to where you are. The region must support all the products run in this demo (note that some of these are global, and not regional, but all are listed for completeness), which are:

Cloud Run
Cloud Spanner
Cloud SQL
Cloud Storage
Container Registry
Dataflow
Firestore
Kubernetes Engine
Pub/Sub

If you do NOT specify a default region in `gcloud init` then you must either set an environment variable for "DEMO_REGION" before running, or pass one in as an argument to the script with the `-r` flag.

The other required flag to pass in is a version string with a -v flag. This is necessary because of how the load generating script is run (kubernetes job). The container won't automatically re-fetch the container if there are changes unless the tag is different. So the version was a necessary evil to represent changes to the container tagging. This string is formatted like: `-v v0.0.1` for example.

Quickstart would be:

`gcloud init`
`python build.py -v v0.0.1 -r us-central1`

Running those two, assuming you have at least editor level permissions to the project you're associated with should deploy all services needed and have everything ready to go.

The final output of the script will contain the URL for the orchestrator script if you want to trigger the back-end manually (instructions for running this manually to follow), as well as the URL for the hosted front-end which is a pretty and animated interface.

Note that this demo as deployed by the build.py script is pretty expensive to run. We hit all the products listed above quite hard. The traffic generated by the demo numbers in the 100,000s of queries per second, and those queries are all tracked through the databases as well as Pub/Sub and Dataflow.

There's a version of the demo you can deploy which relies upon static/cached data rather than running things live, which can be deployed by running build_cached.py instead of build.py. Note that the data is real, in that it was generated by running the full version of the demo, but the results were cached and stored in Firestore. The cached version only uses Cloud Run, Container Registry and Firestore.
